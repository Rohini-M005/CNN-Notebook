{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99316eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in ./venv/lib/python3.11/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in ./venv/lib/python3.11/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in ./venv/lib/python3.11/site-packages (from kaggle) (2025.4.26)\n",
      "Requirement already satisfied: charset-normalizer in ./venv/lib/python3.11/site-packages (from kaggle) (3.4.2)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.11/site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in ./venv/lib/python3.11/site-packages (from kaggle) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in ./venv/lib/python3.11/site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in ./venv/lib/python3.11/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.11/site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in ./venv/lib/python3.11/site-packages (from kaggle) (65.5.0)\n",
      "Requirement already satisfied: six>=1.10 in ./venv/lib/python3.11/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in ./venv/lib/python3.11/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.11/site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in ./venv/lib/python3.11/site-packages (from kaggle) (2.4.0)\n",
      "Requirement already satisfied: webencodings in ./venv/lib/python3.11/site-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b610155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¬‡ï¸ Downloading and unzipping dataset...\n",
      "Dataset URL: https://www.kaggle.com/datasets/andrewmvd/ocular-disease-recognition-odir5k\n",
      "âœ… Dataset downloaded and unzipped.\n",
      "ðŸ“‚ Contents:\n",
      "['ocular-disease-recognition-odir5k.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# Authenticate\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Dataset and path setup\n",
    "dataset_name = 'andrewmvd/ocular-disease-recognition-odir5k'\n",
    "download_path = 'data/odir5k'\n",
    "\n",
    "# Create folder if not exists\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Check if dataset already unzipped (assume a known file/folder from the dataset)\n",
    "expected_folder = os.path.join(download_path, 'ODIR-5K')  # folder inside the dataset\n",
    "if not os.path.exists(expected_folder):\n",
    "    print(\"â¬‡ï¸ Downloading and unzipping dataset...\")\n",
    "    api.dataset_download_files(dataset_name, path=download_path, unzip=True)\n",
    "    print(\"âœ… Dataset downloaded and unzipped.\")\n",
    "else:\n",
    "    print(\"âœ… Dataset already exists and is unzipped.\")\n",
    "\n",
    "# Optional: list files to confirm\n",
    "print(\"ðŸ“‚ Contents:\")\n",
    "print(os.listdir(download_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d636d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset already downloaded.\n",
      "ðŸ“¦ Unzipping dataset...\n",
      "âœ… Unzipping complete.\n",
      "ðŸ“‚ Contents:\n",
      "['preprocessed_images', 'ocular-disease-recognition-odir5k.zip', 'ODIR-5K', 'full_df.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import zipfile\n",
    "\n",
    "# Authenticate\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# Paths\n",
    "dataset_name = 'andrewmvd/ocular-disease-recognition-odir5k'\n",
    "download_path = 'data/odir5k'\n",
    "zip_file_path = os.path.join(download_path, 'ocular-disease-recognition-odir5k.zip')\n",
    "unzipped_folder_path = os.path.join(download_path, 'ODIR-5K')  # adjust if needed\n",
    "\n",
    "# Create download directory if it doesn't exist\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Download if not already downloaded\n",
    "if not os.path.exists(zip_file_path):\n",
    "    print(\"â¬‡ï¸ Downloading dataset...\")\n",
    "    api.dataset_download_files(dataset_name, path=download_path)\n",
    "    print(\"âœ… Download complete.\")\n",
    "else:\n",
    "    print(\"âœ… Dataset already downloaded.\")\n",
    "\n",
    "# Unzip if not already unzipped\n",
    "if not os.path.exists(unzipped_folder_path):\n",
    "    print(\"ðŸ“¦ Unzipping dataset...\")\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(download_path)\n",
    "    print(\"âœ… Unzipping complete.\")\n",
    "else:\n",
    "    print(\"âœ… Dataset already unzipped.\")\n",
    "\n",
    "# List contents to confirm\n",
    "print(\"ðŸ“‚ Contents:\")\n",
    "print(os.listdir(download_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb79660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284a46ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found GPU at: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 23:14:51.252174: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3\n",
      "2025-06-06 23:14:51.252565: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-06-06 23:14:51.252580: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-06-06 23:14:51.252713: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-06-06 23:14:51.252774: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    print(\"WARNING: No GPU Found\")\n",
    "else:\n",
    "    print('âœ… Found GPU at:', device_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d55bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-autotime in ./tf-metal/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: ipython in ./tf-metal/lib/python3.11/site-packages (from ipython-autotime) (9.3.0)\n",
      "Requirement already satisfied: decorator in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (2.19.1)\n",
      "Requirement already satisfied: stack_data in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in ./tf-metal/lib/python3.11/site-packages (from ipython->ipython-autotime) (4.14.0)\n",
      "Requirement already satisfied: wcwidth in ./tf-metal/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->ipython-autotime) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in ./tf-metal/lib/python3.11/site-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./tf-metal/lib/python3.11/site-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./tf-metal/lib/python3.11/site-packages (from stack_data->ipython->ipython-autotime) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./tf-metal/lib/python3.11/site-packages (from stack_data->ipython->ipython-autotime) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in ./tf-metal/lib/python3.11/site-packages (from stack_data->ipython->ipython-autotime) (0.2.3)\n",
      "time: 116 Î¼s (started: 2025-06-06 23:14:55 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee5fe2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 512 ms (started: 2025-06-06 23:14:57 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q imgaug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "405e4172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 407 ms (started: 2025-06-06 23:14:59 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imgaug import augmenters as iaa\n",
    "np.bool = bool  # Fix for imgaug numpy compatibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec6d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./tf-metal/lib/python3.11/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./tf-metal/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: matplotlib in ./tf-metal/lib/python3.11/site-packages (3.10.3)\n",
      "Requirement already satisfied: seaborn in ./tf-metal/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in ./tf-metal/lib/python3.11/site-packages (1.7.0)\n",
      "Requirement already satisfied: keras in ./tf-metal/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./tf-metal/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./tf-metal/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./tf-metal/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./tf-metal/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./tf-metal/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./tf-metal/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./tf-metal/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: absl-py in ./tf-metal/lib/python3.11/site-packages (from keras) (2.3.0)\n",
      "Requirement already satisfied: rich in ./tf-metal/lib/python3.11/site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in ./tf-metal/lib/python3.11/site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in ./tf-metal/lib/python3.11/site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in ./tf-metal/lib/python3.11/site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in ./tf-metal/lib/python3.11/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: six>=1.5 in ./tf-metal/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in ./tf-metal/lib/python3.11/site-packages (from optree->keras) (4.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./tf-metal/lib/python3.11/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./tf-metal/lib/python3.11/site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./tf-metal/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "time: 534 ms (started: 2025-06-06 23:15:02 +05:30)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2a85ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 184 ms (started: 2025-06-06 23:15:04 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import os\n",
    "import csv\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb25dfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 472 Î¼s (started: 2025-06-06 23:15:07 +05:30)\n"
     ]
    }
   ],
   "source": [
    "dataset_path = '/kaggle/input/ocular-disease-recognition-odir5k'\n",
    "number_of_classes = 5\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bf3698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 23:15:09.388755: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-06-06 23:15:09.388801: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.18 s (started: 2025-06-06 23:15:09 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "eff = tf.keras.applications.EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcdf96fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.97 ms (started: 2025-06-06 23:15:13 +05:30)\n"
     ]
    }
   ],
   "source": [
    "# Create an output folder first (run this once)\n",
    "import os\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "# Training stage\n",
    "training_model_save_path = \"outputs/ResNet101.keras\"\n",
    "training_history_save_path = \"outputs/ResNet101.csv\"\n",
    "training_history_plot_save_path = \"outputs/ResNet101.png\"\n",
    "training_confusion_matrix_save_path = \"outputs/confusion_matrix.png\"\n",
    "training_roc_curve_save_path = \"outputs/roc_curve.png\"\n",
    "\n",
    "# Fine-tuning stage\n",
    "fine_tuning_model_save_path = \"outputs/fine_tuning_model.keras\"\n",
    "fine_tuning_history_save_path = \"outputs/fine_tuning_history.csv\"\n",
    "fine_tuning_history_plot_save_path = \"outputs/fine_tuning_history.png\"\n",
    "fine_tuning_confusion_matrix_save_path = \"outputs/fine_tuning_confusion_matrix.png\"\n",
    "fine_tuning_roc_curve_save_path = \"outputs/fine_tuning_roc_curve.png\"\n",
    "\n",
    "# Combined/both training\n",
    "both_training_history_save_path = \"outputs/Both_history.csv\"\n",
    "both_training_confusion_matrix_save_path = \"outputs/both_confusion_matrix.csv\"\n",
    "\n",
    "# Overall CSV summaries\n",
    "accuracy_loss_csv_path = \"outputs/AccuracyLossCurves.csv\"\n",
    "roc_auroc_csv_path = \"outputs/ROCandAUROC.csv\"\n",
    "confusion_matrix_csv_path = \"outputs/ConfusionMat.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7483d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms (started: 2025-06-06 23:15:16 +05:30)\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 40\n",
    "training_learning_rate = 0.0001\n",
    "training_loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "training_optimizer = tf.keras.optimizers.Adam(learning_rate = training_learning_rate)\n",
    "training_metrics = ['accuracy']\n",
    "training_callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(training_model_save_path, save_weights_only=False, save_best_only=True, mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34f4f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available folders/files in dataset_path:\n",
      "\n",
      "['ODIR-5K']\n",
      "time: 1.72 ms (started: 2025-06-06 23:20:17 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the correct dataset path\n",
    "dataset_path = 'data/odir5k/ODIR-5K'  # or 'data/odir5k/preprocessed_images' if you're using that\n",
    "\n",
    "print(\"Available folders/files in dataset_path:\\n\")\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3b753",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/odir5k/data.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m target_dir = \u001b[33m'\u001b[39m\u001b[33mdata/odir5k/ocular\u001b[39m\u001b[33m'\u001b[39m     \u001b[38;5;66;03m# Output directory to organize images\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Load Excel file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexcel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msheet_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSheet1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mopenpyxl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Define keyword-to-class mapping\u001b[39;00m\n\u001b[32m     18\u001b[39m keyword_class_map = {\n\u001b[32m     19\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnormal fundus\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mNormal\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdiabetic retinopathy\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mDiabetes\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmacular degeneration\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mAge-Related Macular Degeneration\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     26\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new2/tf-metal/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new2/tf-metal/lib/python3.11/site-packages/pandas/io/excel/_base.py:1567\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28mself\u001b[39m.engine = engine\n\u001b[32m   1565\u001b[39m \u001b[38;5;28mself\u001b[39m.storage_options = storage_options\n\u001b[32m-> \u001b[39m\u001b[32m1567\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new2/tf-metal/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:553\u001b[39m, in \u001b[36mOpenpyxlReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    550\u001b[39m \u001b[33;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[32m    551\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    552\u001b[39m import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mopenpyxl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m553\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new2/tf-metal/lib/python3.11/site-packages/pandas/io/excel/_base.py:563\u001b[39m, in \u001b[36mBaseExcelReader.__init__\u001b[39m\u001b[34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = IOHandles(\n\u001b[32m    560\u001b[39m     handle=filepath_or_buffer, compression={\u001b[33m\"\u001b[39m\u001b[33mmethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[32m    561\u001b[39m )\n\u001b[32m    562\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m._workbook_class)):\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    565\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.handles.handle, \u001b[38;5;28mself\u001b[39m._workbook_class):\n\u001b[32m    568\u001b[39m     \u001b[38;5;28mself\u001b[39m.book = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/new2/tf-metal/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/odir5k/data.xlsx'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 77.4 ms (started: 2025-06-06 23:58:49 +05:30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Set random seed\n",
    "random.seed(42)\n",
    "\n",
    "# Paths\n",
    "\n",
    "dataset_path = 'data/odir5k/ODIR-5K'  # Folder that has 'Training Images' and 'Testing Images'\n",
    "excel_path = 'data/odir5k/ODIR-5K/data.xlsx'  # Corrected Excel file path\n",
    "target_dir = 'data/odir5k/ocular'     # Output directory to organize images\n",
    "\n",
    "# Load Excel file\n",
    "df = pd.read_excel(excel_path, sheet_name='Sheet1', engine='openpyxl')\n",
    "\n",
    "# Define keyword-to-class mapping\n",
    "keyword_class_map = {\n",
    "    'normal fundus': 'Normal',\n",
    "    'diabetic retinopathy': 'Diabetes',\n",
    "    'proliferative retinopathy': 'Diabetes',\n",
    "    'glaucoma': 'Glaucoma',\n",
    "    'cataract': 'Cataract',\n",
    "    'age-related': 'Age-Related Macular Degeneration',\n",
    "    'macular degeneration': 'Age-Related Macular Degeneration'\n",
    "}\n",
    "\n",
    "# Final class folders to be created\n",
    "target_classes = [\n",
    "    'Age-Related Macular Degeneration',\n",
    "    'Normal',\n",
    "    'Diabetes',\n",
    "    'Glaucoma',\n",
    "    'Cataract',\n",
    "    'Multilabel',\n",
    "    'Other'\n",
    "]\n",
    "\n",
    "# Create output folders\n",
    "for cls in target_classes:\n",
    "    os.makedirs(os.path.join(target_dir, cls), exist_ok=True)\n",
    "\n",
    "# Folders to search for images\n",
    "image_folders = ['Training Images', 'Testing Images']\n",
    "\n",
    "# Helper function to extract matched class(es)\n",
    "def extract_class_set(text):\n",
    "    if pd.isna(text):\n",
    "        return set()\n",
    "\n",
    "    text = str(text).lower().replace('ï¼Œ', ',')  # Normalize punctuation\n",
    "    parts = [part.strip() for part in text.split(',') if part.strip()]\n",
    "    \n",
    "    matched_classes = set()\n",
    "    for part in parts:\n",
    "        for keyword, mapped_class in keyword_class_map.items():\n",
    "            if keyword in part:\n",
    "                matched_classes.add(mapped_class)\n",
    "\n",
    "    if len(parts) > 1:\n",
    "        matched_classes.add('_MULTILABEL_')\n",
    "\n",
    "    return matched_classes\n",
    "\n",
    "# Process each row in the Excel file\n",
    "for _, row in df.iterrows():\n",
    "    for eye_side, eye_col, diag_col in [('left', 'Left-Fundus', 'Left-Diagnostic Keywords'),\n",
    "                                        ('right', 'Right-Fundus', 'Right-Diagnostic Keywords')]:\n",
    "        img_name = row[eye_col]\n",
    "        if pd.isna(img_name):\n",
    "            continue\n",
    "\n",
    "        # Find image path in folders\n",
    "        image_path = None\n",
    "        for folder in image_folders:\n",
    "            test_path = os.path.join(dataset_path, folder, img_name)\n",
    "            if os.path.exists(test_path):\n",
    "                image_path = test_path\n",
    "                break\n",
    "        if not image_path:\n",
    "            continue\n",
    "\n",
    "        # Determine classification\n",
    "        matched_classes = extract_class_set(row[diag_col])\n",
    "\n",
    "        if '_MULTILABEL_' in matched_classes or len(matched_classes) > 1:\n",
    "            class_folder = 'Multilabel'\n",
    "        elif len(matched_classes) == 1:\n",
    "            class_folder = list(matched_classes - {'_MULTILABEL_'})[0]\n",
    "        else:\n",
    "            class_folder = 'Other'\n",
    "\n",
    "        # Destination path\n",
    "        dest_path = os.path.join(target_dir, class_folder, f\"{eye_side}_{img_name}\")\n",
    "\n",
    "        # Copy image\n",
    "        if not os.path.exists(dest_path):\n",
    "            shutil.copy(image_path, dest_path)\n",
    "\n",
    "# Done\n",
    "print(f\"\\nâœ… Final dataset organized in: {target_dir}\")\n",
    "print(\"ðŸ“‚ Subfolders created for each class with eye-wise image separation.\")\n",
    "print(\"ðŸ“‚ Multilabel and unclassified images handled separately.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
